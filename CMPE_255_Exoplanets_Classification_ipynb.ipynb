{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Shashanksai6/255_finalproject/blob/main/CMPE_255_Exoplanets_Classification_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages"
   ],
   "metadata": {
    "id": "ubu8NV4r-UKD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yp0eKFUn95Qy"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Installing dependencies\n",
    "!pip install MarkupSafe==2.1.1 \n",
    "!pip install lazypredict\n",
    "!pip install -U pandas-profiling"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5-qDyLj99_hW",
    "outputId": "5d57ef51-6978-48a0-d3bc-24993fb168da"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting MarkupSafe==2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Installing collected packages: MarkupSafe\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.2\n",
      "    Uninstalling MarkupSafe-2.1.2:\n",
      "      Successfully uninstalled MarkupSafe-2.1.2\n",
      "Successfully installed MarkupSafe-2.1.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting lazypredict\n",
      "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.65.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.5.3)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.7.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (3.3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.22.4)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (0.40.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->lazypredict) (1.16.0)\n",
      "Installing collected packages: lazypredict\n",
      "Successfully installed lazypredict-0.2.12\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pandas-profiling\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m324.4/324.4 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.1.2-py2.py3-none-any.whl (345 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m345.9/345.9 kB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.12.2)\n",
      "Collecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting imagehash==4.3.1\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m296.5/296.5 kB\u001B[0m \u001B[31m17.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m679.5/679.5 kB\u001B[0m \u001B[31m33.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.22.4)\n",
      "Collecting matplotlib<3.7,>=3.2\n",
      "  Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.8/11.8 MB\u001B[0m \u001B[31m60.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting multimethod<1.10,>=1.4\n",
      "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (3.1.2)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.5.3)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m102.7/102.7 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests<2.29,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (2.27.1)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (0.13.5)\n",
      "Collecting scipy<1.10,>=1.4.1\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m33.7/33.7 MB\u001B[0m \u001B[31m34.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting typeguard<2.14,>=2.13.2\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (6.0)\n",
      "Collecting tqdm<4.65,>=4.48.2\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: pydantic<1.11,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas-profiling) (1.10.7)\n",
      "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.4.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (3.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (23.1.0)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.7/4.7 MB\u001B[0m \u001B[31m26.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (23.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (4.39.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.7,>=3.2->ydata-profiling->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<1.6,>1.1->ydata-profiling->pandas-profiling) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas-profiling) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<2.29,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.12)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.14,>=0.13.2->ydata-profiling->pandas-profiling) (0.5.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->ydata-profiling->pandas-profiling) (1.16.0)\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27096 sha256=e8d4e81aa829abc45778d254407d9742ad37fb8bf8d4046c2c0d0919e2a418e6\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, typeguard, tqdm, tangled-up-in-unicode, scipy, multimethod, matplotlib, imagehash, visions, phik, ydata-profiling, pandas-profiling\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "Successfully installed htmlmin-0.1.12 imagehash-4.3.1 matplotlib-3.6.3 multimethod-1.9.1 pandas-profiling-3.6.6 phik-0.12.3 scipy-1.9.3 tangled-up-in-unicode-0.2.0 tqdm-4.64.1 typeguard-2.13.3 visions-0.7.5 ydata-profiling-4.1.2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "matplotlib",
         "mpl_toolkits"
        ]
       }
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Import packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Sklearn Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Exploratory Data Analysis (EDA) \n",
    "from pandas_profiling import ProfileReport\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ],
   "metadata": {
    "id": "PrRAzuDI-IF9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Objective:\n",
    "\n",
    "In this project, our goal is to build a model that can predict the existence of an exoplanet (i.e. a planet that orbits a distant star system) given the light intensity readings from that star over time. The dataset we’ll be using comes from NASA’s Kepler telescope currently in space. This project will demonstrate how predictive classication modeling will helps to discover does planat is exoplanate or not."
   ],
   "metadata": {
    "id": "_QdqZ8lI-pCM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Extraction\n",
    "\n",
    "Data extraction is the process of acquiring and processing raw data of various forms and types to improve the operational paradigms of an organization.\n",
    "\n",
    "It is perhaps the most important operation of the Extract/Transform/Load (ETL) process because it is the foundation for critical analyses and  decision making processes. It enables consolidation, analysis and refining of data so that it can be converted into meaningful information that can be stored for further use and manipulation. The extracted data can help in decision making, customer base expansion, service improvements, predicting sales and optimizing costs, among other things.\n",
    "\n",
    "In our use case, we are using NASA-Caltech API (https://exoplanetarchive.ipac.caltech.edu/docs/program_interfaces.html) to retrive the information captured by Kaper telescope. We transformed the JSON data from API to CSV using Excel to make it available for Machine Learning analysis."
   ],
   "metadata": {
    "id": "eAWLQXHC-qVu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "df = pd.read_csv('/content/drive/My Drive/dataset/exoplanet/exoplanets_nasa.csv')\n",
    "df = pd.DataFrame(np.repeat(df.values, 25, axis=0))\n",
    "\n",
    "df.head(2)\n",
    "df.shape[0]"
   ],
   "metadata": {
    "id": "KPVxQS76-xZz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis"
   ],
   "metadata": {
    "id": "JwjNIH8k_Xh2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, html={'style':{'full_width':True}})\n",
    "#profile.to_notebook_iframe()\n",
    "profile.to_file(\"/content/drive/My Drive/dataset/expanded_exoplanets_profile_report.html\")"
   ],
   "metadata": {
    "id": "ss9Ue77A_bo_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature Engineering and Transformation\n",
    "\n",
    "Feature engineering is the process of transforming features, extracting features, and creating new variables from the original data, to train machine learning models.\n",
    "\n",
    "Data in its original format can almost never be used straightaway to train classification or regression models. Instead, data scientists devote a huge chunk of their time to data preprocessing to train machine learning algorithms. Feature engineering is key to improving the performance of machine learning algorithms. Yet, it is very time-consuming. Fortunately, there are many Python libraries that we can use for data preparation.\n",
    "\n",
    "Some techniques above might work better with some algorithms or datasets, while some of them might be beneficial in all casses. Based on current situtation, There are couple of transformation takes place on data based followed as:\n",
    "\n",
    "- Change the columns name\n",
    "- Dropped some columns\n",
    "- Transformed target variables\n",
    "- Handling Missing values\n",
    "- Remove Duplicate instances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Change the columns name\n",
    "df = df.rename(columns={'kepid': 'KepID',\n",
    "                        'kepoi_name': 'KOIName',\n",
    "                        'kepler_name': 'KeplerName',\n",
    "                        'koi_disposition': 'ExoplanetArchiveDisposition',\n",
    "                        'koi_pdisposition': 'DispositionUsingKeplerData',\n",
    "                        'koi_score': 'DispositionScore',\n",
    "                        'koi_fpflag_nt': 'NotTransit-LikeFalsePositiveFlag',\n",
    "                        'koi_fpflag_ss': 'koi_fpflag_ss',\n",
    "                        'koi_fpflag_co': 'CentroidOffsetFalsePositiveFlag',\n",
    "                        'koi_fpflag_ec': 'EphemerisMatchIndicatesContaminationFalsePositiveFlag',\n",
    "                        'koi_period': 'OrbitalPeriod.days',\n",
    "                        'koi_period_err1': 'OrbitalPeriodUpperUnc.days',\n",
    "                        'koi_period_err2': 'OrbitalPeriodLowerUnc.days',\n",
    "                        'koi_time0bk': 'TransitEpoch.BKJD',\n",
    "                        'koi_time0bk_err1': 'TransitEpochUpperUnc.BKJD',\n",
    "                        'koi_time0bk_err2': 'TransitEpochLowerUnc.BKJD',\n",
    "                        'koi_impact': 'ImpactParamete',\n",
    "                        'koi_impact_err1': 'ImpactParameterUpperUnc',\n",
    "                        'koi_impact_err2': 'ImpactParameterLowerUnc',\n",
    "                        'koi_duration': 'TransitDuration.hrs',\n",
    "                        'koi_duration_err1': 'TransitDurationUpperUnc.hrs',\n",
    "                        'koi_duration_err2': 'TransitDurationLowerUnc.hrs',\n",
    "                        'koi_depth': 'TransitDepth.ppm',\n",
    "                        'koi_depth_err1': 'TransitDepthUpperUnc.ppm',\n",
    "                        'koi_depth_err2': 'TransitDepthLowerUnc.ppm',\n",
    "                        'koi_prad': 'PlanetaryRadius.Earthradii',\n",
    "                        'koi_prad_err1': 'PlanetaryRadiusUpperUnc.Earthradii',\n",
    "                        'koi_prad_err2': 'PlanetaryRadiusLowerUnc.Earthradii',\n",
    "                        'koi_teq': 'EquilibriumTemperature.K',\n",
    "                        'koi_teq_err1': 'EquilibriumTemperatureUpperUnc.K',\n",
    "                        'koi_teq_err2': 'EquilibriumTemperatureLowerUnc.K',\n",
    "                        'koi_insol': 'InsolationFlux.Earthflux',\n",
    "                        'koi_insol_err1': 'InsolationFluxUpperUnc.Earthflux',\n",
    "                        'koi_insol_err2': 'InsolationFluxLowerUnc.Earthflux',\n",
    "                        'koi_model_snr': 'TransitSignal-to-Nois',\n",
    "                        'koi_tce_plnt_num': 'TCEPlanetNumbe',\n",
    "                        'koi_tce_delivname': 'TCEDeliver',\n",
    "                        'koi_steff': 'StellarEffectiveTemperature.K',\n",
    "                        'koi_steff_err1': 'StellarEffectiveTemperatureUpperUnc.K',\n",
    "                        'koi_steff_err2': 'StellarEffectiveTemperatureLowerUnc.K',\n",
    "                        'koi_slogg': 'StellarSurfaceGravity.log10(cm/s**2)',\n",
    "                        'koi_slogg_err1': 'StellarSurfaceGravityUpperUnc.log10(cm/s**2)',\n",
    "                        'koi_slogg_err2': 'StellarSurfaceGravityLowerUnc.log10(cm/s**2)',\n",
    "                        'koi_srad': 'StellarRadius.Solarradii',\n",
    "                        'koi_srad_err1': 'StellarRadiusUpperUnc.Solarradii',\n",
    "                        'koi_srad_err2': 'StellarRadiusLowerUnc.Solarradii',\n",
    "                        'ra': 'RA.decimaldegrees',\n",
    "                        'dec': 'Decdecimaldegrees',\n",
    "                        'koi_kepmag': 'Kepler-band.mag'\n",
    "                        })\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#2. Transformed target variables\n",
    "df['ExoplanetCandidate'] = df['DispositionUsingKeplerData'].apply(lambda x: 1 if x == 'CANDIDATE' else 0)\n",
    "#df['ExoplanetConfirmed'] = df['ExoplanetArchiveDisposition'].apply(lambda x: 2 if x == 'CONFIRMED' else 1 if x == 'CANDIDATE' else 0 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#3. Dropped some columns\n",
    "df.drop(columns=['KeplerName', 'KOIName', 'EquilibriumTemperatureUpperUnc.K',\n",
    "                 'KepID', 'ExoplanetArchiveDisposition', 'DispositionUsingKeplerData',\n",
    "                 'NotTransit-LikeFalsePositiveFlag', 'koi_fpflag_ss', 'CentroidOffsetFalsePositiveFlag',\n",
    "                 'EphemerisMatchIndicatesContaminationFalsePositiveFlag', 'TCEDeliver',\n",
    "                 'EquilibriumTemperatureLowerUnc.K'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#4. Handling Missing values\n",
    "df.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#5. Remove Duplicate instances\n",
    "df.drop_duplicates(inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
